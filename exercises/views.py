"""
Vues pour la gestion des exercices.
"""
from rest_framework import viewsets, status
from rest_framework.decorators import action
from rest_framework.response import Response
from rest_framework.permissions import IsAuthenticated, AllowAny
from django.utils import timezone
from django.db import models
from .models import Exercise, ExerciseAttempt
from .serializers import (
    ExerciseListSerializer, ExerciseDetailSerializer, ExerciseCreateSerializer, ExerciseAnswerSerializer,
    ExerciseResultSerializer, ExerciseAttemptSerializer
)


class ExerciseViewSet(viewsets.ModelViewSet):
    """ViewSet pour les exercices."""
    
    queryset = Exercise.objects.filter(is_active=True)
    
    def get_permissions(self):
        if self.action in ['create', 'update', 'partial_update', 'destroy']:
            return [IsAuthenticated()]
        return [AllowAny()]
    
    def get_serializer_class(self):
        if self.action in ['create', 'update', 'partial_update']:
            return ExerciseCreateSerializer
        if self.action == 'retrieve':
            return ExerciseDetailSerializer
        return ExerciseListSerializer
    
    def perform_create(self, serializer):
        """Associer l'exercice à l'utilisateur qui l'a créé."""
        serializer.save(creator=self.request.user)
    
    def get_queryset(self):
        user = self.request.user
        
        # Base queryset: only active exercises
        queryset = Exercise.objects.filter(is_active=True)
        
        if user.is_authenticated:
            if user.user_type == 'admin' or user.is_superuser:
                # Admins see everything
                pass
            else:
                # Students and Teachers see:
                # 1. Exercises created by an admin
                # 2. Exercises they created themselves (unless it's AI generated by someone else)
                # 3. AI generated exercises ONLY if they are the creator
                
                queryset = queryset.filter(
                    models.Q(creator__user_type='admin') | 
                    models.Q(creator=user)
                )
                
                # Further restriction: if is_ai_generated, must be the creator
                # (This is already covered by the filter above, but let's be explicit if needed)
                # Actually, the logic is: 
                # (creator is admin) OR (creator is me)
                # This automatically hides AI exercises of others (since they aren't admin and aren't me)
        else:
            # Public/unauthenticated view: only admin exercises
            queryset = queryset.filter(creator__user_type='admin')

        # Filtrer par matière
        subject = self.request.query_params.get('subject', None)
        if subject:
            queryset = queryset.filter(subject__slug=subject)
        
        # Filtrer par niveau (paramètre URL)
        level_param = self.request.query_params.get('level', None)
        if level_param:
            queryset = queryset.filter(level=level_param)
            
        # Restriction d'accès par niveau de l'élève
        if user.is_authenticated and user.user_type == 'student':
            from users.utils import get_allowed_levels
            allowed_levels = get_allowed_levels(user.level)
            # L'élève peut voir les exercices de son niveau (et inférieurs), 
            # MAIS aussi tous les exercices qu'il a générés lui-même, peu importe le niveau
            queryset = queryset.filter(
                models.Q(level__in=allowed_levels) | 
                models.Q(creator=user)
            )
        
        # Filtrer par difficulté
        difficulty = self.request.query_params.get('difficulty', None)
        if difficulty:
            queryset = queryset.filter(difficulty=difficulty)
        
        # Filtrer par leçon
        lesson = self.request.query_params.get('lesson', None)
        if lesson:
            queryset = queryset.filter(lesson__slug=lesson)
        
        return queryset.distinct()
    
    @action(detail=True, methods=['post'], permission_classes=[IsAuthenticated])
    def submit(self, request, pk=None):
        """Soumettre une réponse à un exercice."""
        exercise = self.get_object()
        serializer = ExerciseAnswerSerializer(data=request.data)
        
        if not serializer.is_valid():
            return Response(serializer.errors, status=status.HTTP_400_BAD_REQUEST)
        
        answer = serializer.validated_data['answer']
        time_spent = serializer.validated_data.get('time_spent', 0)
        hints_used = serializer.validated_data.get('hints_used', 0)
        
        # Vérifier la réponse
        correct_answers = exercise.correct_answers
        
        # Calculate partial score for QCM arrays
        if exercise.exercise_type == 'qcm' and isinstance(answer, list) and isinstance(correct_answers, list):
            correct_count: int = 0
            total_questions = len(correct_answers)
            
            # Normalize correct answers
            norm_correct = []
            for c in correct_answers:
                if isinstance(c, str) and c.upper() in ['A', 'B', 'C', 'D']:
                    val = str(ord(c.upper()) - 65)
                    norm_correct.append(val)
                else:
                    norm_correct.append(str(c))
                    
            # Normalize provided answers
            norm_answer = []
            for a in answer:
                if isinstance(a, int) or (isinstance(a, str) and a.isdigit()):
                    norm_answer.append(str(a))
                else:
                    norm_answer.append(str(a).upper())
            
            # Count matches
            for i in range(min(len(norm_answer), len(norm_correct))):
                if norm_answer[i] == norm_correct[i]:
                    correct_count += 1
                    
            is_correct = correct_count == total_questions
            score_out_of_total = correct_count
            max_possible = total_questions
        else:
            is_correct = self._check_answer(answer, correct_answers, exercise.exercise_type)
            score_out_of_total = exercise.points if is_correct else 0
            max_possible = exercise.points
        
        # Calculer le score (legacy approach for non-qcm arrays)
        score = score_out_of_total
        if hints_used > 0:
            score = max(0, score - (hints_used * 2))  # Pénalité pour indices
        
        # Créer la tentative
        attempt = ExerciseAttempt.objects.create(
            exercise=exercise,
            student=request.user,
            answer=answer,
            is_correct=is_correct,
            score=score,
            time_spent=time_spent,
            hints_used=hints_used
        )
        
        result = {
            'is_correct': is_correct,
            'score': score,
            'max_score': max_possible,
            'correct_answer': correct_answers,
            'explanation': exercise.explanation,
            'message': 'Bravo !' if is_correct else 'Exercice terminé'
        }
        
        return Response(result)
    
    def _check_answer(self, answer, correct_answers, exercise_type):
        """Vérifier si la réponse est correcte selon le type d'exercice."""
        if exercise_type == 'qcm':
            # Handle AI generated list of letters vs list of integers
            if isinstance(answer, list) and isinstance(correct_answers, list):
                if len(answer) != len(correct_answers):
                    return False
                
                norm_answer = []
                for a in answer:
                    if isinstance(a, int) or (isinstance(a, str) and a.isdigit()):
                        norm_answer.append(str(a))
                    else:
                        norm_answer.append(str(a).upper())
                        
                norm_correct = []
                for c in correct_answers:
                    if isinstance(c, str) and c.upper() in ['A', 'B', 'C', 'D']:
                        val = str(ord(c.upper()) - 65)
                        norm_correct.append(val)
                    else:
                        norm_correct.append(str(c))
                        
                return norm_answer == norm_correct
            # Handle legacy string/int fallback
            if isinstance(answer, int) and isinstance(correct_answers, str):
                if correct_answers.upper() in ['A', 'B', 'C', 'D']:
                    return str(answer) == str(ord(correct_answers.upper()) - 65)
            
            # Direct string comparison
            return str(answer) == str(correct_answers)
        elif exercise_type == 'text':
            return answer.lower().strip() == correct_answers.lower().strip()
        elif exercise_type == 'number':
            try:
                return float(answer) == float(correct_answers)
            except (ValueError, TypeError):
                return False
        elif exercise_type == 'matching':
            return answer == correct_answers
        elif exercise_type == 'fill_blank':
            return answer == correct_answers
        elif exercise_type == 'ordering':
            return answer == correct_answers
        return False
    
    @action(detail=False, methods=['get'], permission_classes=[IsAuthenticated])
    def my_attempts(self, request):
        """Récupérer les tentatives de l'élève connecté."""
        attempts = ExerciseAttempt.objects.filter(student=request.user)
        serializer = ExerciseAttemptSerializer(attempts, many=True)
        return Response(serializer.data)
    
    @action(detail=False, methods=['get'])
    def by_lesson(self, request):
        """Récupérer les exercices groupés par leçon."""
        from lessons.models import Lesson
        
        lessons = {}
        for lesson in Lesson.objects.filter(is_active=True):
            exercises = Exercise.objects.filter(lesson=lesson, is_active=True)
            if exercises.exists():
                lessons[lesson.title] = ExerciseListSerializer(exercises, many=True).data
        return Response(lessons)


